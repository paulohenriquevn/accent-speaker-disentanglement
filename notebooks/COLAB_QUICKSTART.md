# ðŸš€ Guia RÃ¡pido - Notebook Colab L4

## ðŸ“‹ PrÃ©-requisitos

1. **Conta Google** com acesso ao Colab
2. **GPU L4** disponÃ­vel (Colab Pro/Pro+ recomendado)
3. **~25GB espaÃ§o livre** no Google Drive (para sincronizar resultados)
4. **2-3 horas** de tempo de execuÃ§Ã£o contÃ­nuo

---

## ðŸŽ¯ InÃ­cio RÃ¡pido (5 minutos)

### 1. Abrir Notebook

```
1. Fazer upload do arquivo: stage1_5_colab_L4.ipynb
2. Abrir no Google Colab
3. Runtime â†’ Change runtime type â†’ GPU â†’ L4
4. Runtime â†’ Run all (ou Ctrl+F9)
```

### 2. Aguardar ExecuÃ§Ã£o

- â±ï¸ **Setup**: ~10 min
- â±ï¸ **Dataset**: ~5 min (sintÃ©tico) ou ~30 min (real)
- â±ï¸ **Features**: ~60-90 min (backbone Ã© o mais lento)
- â±ï¸ **Probes**: ~15 min
- â±ï¸ **Analysis**: ~5 min

**Total**: ~2-3 horas

### 3. Baixar Resultados

Ao final, serÃ¡ gerado `stage1_5_results.zip` contendo:
- `report/stage1_5_report.md` â† **LEIA ESTE**
- `artifacts/analysis/` (mÃ©tricas + heatmaps)
- `config/` (configuraÃ§Ã£o usada)

---

## ðŸ“Š Interpretando Resultados

### MÃ©tricas Principais

```markdown
| Layer              | Accent F1 | Leak Aâ†’S | Text Drop |
|--------------------|-----------|----------|-----------|
| backbone:decoder_08| 0.724     | 0.089    | 0.045     |
```

- **Accent F1**: Quanto maior, melhor (>0.55 = GO)
- **Leak Aâ†’S**: Quanto menor, melhor (<chance+0.07 = OK)
- **Text Drop**: Quanto menor, melhor (<0.10 = robusto)

### DecisÃ£o GO/NOGO

No relatÃ³rio, procure:

```markdown
## Decision

- **Best representation:** backbone:decoder_block_08
- **Decision:** GO
- **Rationale:** Layer decoder_block_08 passes GO thresholds (F1=0.72, leakage=0.09, text_drop=0.05).
```

#### GO (Strong) âœ…
- F1 â‰¥ 0.55
- Leakage baixo
- **AÃ§Ã£o**: Prosseguir para Stage 2 (LoRA)

#### GO (Conditional) âš ï¸
- F1 â‰¥ 0.45
- Leakage moderado
- **AÃ§Ã£o**: Stage 2 com regularizaÃ§Ã£o adversarial

#### NOGO âŒ
- F1 < 0.40 em todos os layers
- **AÃ§Ã£o**: Ajustar dataset ou backbone

---

## ðŸ”§ CustomizaÃ§Ã£o

### Usar Seu Dataset

#### OpÃ§Ã£o 1: Dataset PÃºblico (Recomendado)

```python
# CÃ©lula "download-dataset"
USE_SYNTHETIC = False
DATASET_URL = "https://seu-servidor.com/dataset.zip"
```

**Estrutura esperada do ZIP**:
```
dataset.zip
â”œâ”€â”€ wav/
â”‚   â”œâ”€â”€ spkNE01/
â”‚   â”‚   â”œâ”€â”€ t01.wav
â”‚   â”‚   â”œâ”€â”€ t02.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ spkSE01/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ metadata.csv
â””â”€â”€ texts.json (opcional)
```

**metadata.csv**:
```csv
utt_id,speaker,accent,text_id,rel_path
spkNE01_t01,spkNE01,NE,t01,spkNE01/t01.wav
spkNE01_t02,spkNE01,NE,t02,spkNE01/t02.wav
...
```

#### OpÃ§Ã£o 2: Upload Manual

```python
# ApÃ³s cÃ©lula "clone-repo"
from google.colab import files
uploaded = files.upload()  # Upload do seu dataset.zip

!unzip -q dataset.zip -d data/
```

### Ajustar Layers do Backbone

```python
# CÃ©lula "extract-backbone"
LAYERS = [
    "text_encoder_out",      # Encoder textual
    "decoder_block_02",      # Layers iniciais
    "decoder_block_04",
    "decoder_block_08",      # Layers mÃ©dios
    "decoder_block_12",
    "decoder_block_16",      # Layers finais
    "pre_vocoder"            # Antes do vocoder
]
```

**Dica**: Mais layers = mais tempo. Comece com 5-7 layers.

### Ajustar Config

```python
# Criar config customizado
!cp config/stage1_5.yaml config/my_config.yaml

# Editar (exemplo: mudar thresholds)
import yaml
with open("config/my_config.yaml", "r") as f:
    cfg = yaml.safe_load(f)

cfg["experiment"]["min_f1_go"] = 0.60  # Mais rigoroso
cfg["experiment"]["leakage_margin_pp"] = 5  # Mais rigoroso

with open("config/my_config.yaml", "w") as f:
    yaml.dump(cfg, f)

# Usar config customizado
!stage1_5 run config/my_config.yaml
```

---

## ðŸ› Problemas Comuns

### 1. GPU NÃ£o DisponÃ­vel

**Erro**: `RuntimeError: CUDA not available`

**SoluÃ§Ãµes**:
- Runtime â†’ Change runtime type â†’ GPU â†’ L4
- Se L4 indisponÃ­vel, usar T4 (mais lento)
- Colab Pro tem mais disponibilidade

### 2. CUDA Out of Memory

**Erro**: `torch.cuda.OutOfMemoryError`

**SoluÃ§Ãµes**:

```python
# SoluÃ§Ã£o 1: Usar float16 (economiza 50% VRAM)
!stage1_5 features backbone ... --dtype float16

# SoluÃ§Ã£o 2: Remover Flash Attention
!stage1_5 features backbone ... --attn-implementation eager

# SoluÃ§Ã£o 3: Processar em lotes
# Dividir manifest em chunks de 20 utterances
!split -l 20 data/manifest.jsonl data/chunk_
# Processar cada chunk separadamente
```

### 3. Qwen-TTS NÃ£o Instalado

**Erro**: `ModuleNotFoundError: No module named 'qwen_tts'`

**SoluÃ§Ã£o**:
```python
!pip install -U qwen-tts
# Reiniciar runtime se necessÃ¡rio
```

### 4. Fixes NÃ£o Aplicados

**Erro**: `TypeError: unexpected keyword argument 'input_ids'`

**SoluÃ§Ã£o**: Verificar cÃ©lula "apply-fixes" executou corretamente. Re-executar se necessÃ¡rio.

### 5. Dataset Muito Pequeno

**Aviso**: `Warning: Dataset has only X speakers`

**SoluÃ§Ã£o**: MÃ­nimo recomendado:
- 3 accents
- 8 speakers/accent (24 total)
- 30 texts/speaker

Para testes, sintÃ©tico funciona, mas resultados nÃ£o sÃ£o cientÃ­ficos.

---

## ðŸ“ˆ OtimizaÃ§Ãµes para L4

### JÃ¡ Implementadas no Notebook

âœ… **Mixed Precision**: bfloat16 (reduz VRAM 50%)  
âœ… **Flash Attention 3**: kernels otimizados  
âœ… **Cache Management**: limpa VRAM entre etapas  
âœ… **Batch Processing**: processa em lotes eficientes  

### OtimizaÃ§Ãµes Adicionais (Opcional)

```python
# 1. Compilar modelo (PyTorch 2.0+)
# Adicionar antes de extraÃ§Ã£o
model = torch.compile(model, mode="max-autotune")

# 2. Usar gradient checkpointing
# No config
cfg["backbone"]["gradient_checkpointing"] = True

# 3. Quantizar modelo (experimental)
from transformers import BitsAndBytesConfig
quant_config = BitsAndBytesConfig(load_in_8bit=True)
model = AutoModel.from_pretrained(checkpoint, quantization_config=quant_config)
```

---

## ðŸŽ“ Dicas de Uso

### Para Experimentos RÃ¡pidos

```python
# 1. Usar dataset sintÃ©tico pequeno
accents = ["NE", "SE"]  # apenas 2
speakers_per_accent = 3  # mÃ­nimo
texts_per_speaker = 5    # poucos textos

# 2. Extrair apenas 3 layers
LAYERS = ["text_encoder_out", "decoder_block_08", "pre_vocoder"]

# 3. Pular SSL (economiza ~10 min)
# Comentar cÃ©lula "extract-ssl"
```

**Tempo total**: ~30-45 min

### Para Resultados CientÃ­ficos

```python
# 1. Dataset real com mÃ­nimo:
# - 3 accents
# - 8 speakers/accent
# - 30 texts comuns

# 2. Extrair 7-10 layers
LAYERS = [
    "text_encoder_out",
    "decoder_block_02", "decoder_block_04",
    "decoder_block_08", "decoder_block_12",
    "decoder_block_16", "decoder_block_20",
    "pre_vocoder"
]

# 3. Incluir todas as features (SSL, ECAPA, etc)
```

**Tempo total**: ~2-3 horas

---

## ðŸ’¾ Backup de SessÃ£o

Google Colab pode desconectar apÃ³s 12h. Para preservar trabalho:

```python
# 1. Sincronizar com Drive periodicamente
!cp -r artifacts/ /content/drive/MyDrive/stage1_5_backup/

# 2. Salvar checkpoints
!zip -r checkpoint_$(date +%H%M).zip artifacts/features/

# 3. Monitorar tempo restante
import time
start = time.time()
# ... executar pipeline ...
elapsed = (time.time() - start) / 3600
print(f"Tempo decorrido: {elapsed:.1f}h")
```

---

## ðŸ“ž Suporte

### Logs Detalhados

```python
import logging
logging.basicConfig(level=logging.DEBUG)
!stage1_5 run config/stage1_5.yaml 2>&1 | tee stage1_5.log
```

### Verificar InstalaÃ§Ã£o

```python
# Verificar versÃµes
!pip show qwen-tts transformers torch

# Verificar layers disponÃ­veis
from stage1_5.backbone.huggingface import HuggingFaceBackboneAdapter, HFAttachConfig
adapter = HuggingFaceBackboneAdapter(HFAttachConfig(checkpoint="Qwen/..."))
print(list(dict(adapter.model.named_modules()).keys())[:20])
```

### Reportar Problemas

Se encontrar bugs:
1. Salvar logs completos
2. Anotar: versÃµes (torch, qwen-tts), GPU usada, erro exato
3. Abrir issue no GitHub com logs

---

## âœ… Checklist de Sucesso

Ao final da execuÃ§Ã£o, vocÃª deve ter:

- [ ] `stage1_5_results.zip` baixado
- [ ] `report/stage1_5_report.md` legÃ­vel
- [ ] DecisÃ£o GO/NOGO clara
- [ ] Heatmaps visualizados
- [ ] MÃ©tricas CSV com ~50-100 linhas
- [ ] Best layer identificado (se GO)

Se tudo OK â†’ **Pronto para Stage 2!** ðŸŽ‰

---

## ðŸš€ PrÃ³ximos Passos

### Se GO (Strong)

1. Documentar layer recomendado
2. Preparar dataset para Stage 2 (LoRA training)
3. Definir arquitetura LoRA (rank, alpha)
4. ComeÃ§ar experimentos de controle

### Se GO (Conditional)

1. Implementar regularizaÃ§Ã£o adversarial
2. Adicionar probes auxiliares durante treino
3. Monitorar leakage em tempo real

### Se NOGO

1. Analisar por que separabilidade Ã© baixa:
   - Dataset muito pequeno?
   - Accents muito similares?
   - Backbone inadequado?
2. Tentar:
   - Aumentar dataset
   - Usar outro backbone (VALL-E, Bark)
   - Redefinir categorias de accent

---

**ðŸŽ¯ Objetivo alcanÃ§ado**: Validar se backbone TTS Ã© adequado para controle explÃ­cito de sotaque antes de investir em treinamento LoRA!

---

**Ãšltima atualizaÃ§Ã£o**: 2026-02-11  
**Autor**: Claude (Anthropic)  
**VersÃ£o do notebook**: 1.0 (otimizado para L4)
