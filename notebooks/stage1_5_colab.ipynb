{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1.5 — Colab Runner\n",
    "This notebook automates the Stage 1.5 latent separability audit (Accent × Speaker) inside Google Colab.\n",
    "\n",
    "**Pipeline overview**\n",
    "1. (Optional) Mount Google Drive to access private datasets/checkpoints.\n",
    "2. Clone this repository (or pull from your fork).\n",
    "3. Install dependencies with `pip install -e .[dev]`.\n",
    "4. Ensure `data/manifest.jsonl` and referenced audio files exist.\n",
    "5. Run the feature extractors (acoustic, ECAPA, SSL, backbone).\n",
    "6. Execute `stage1_5 run` to train probes, compute leakage/RSA/CKA, and render the GO/NOGO report.\n",
    "7. Download artifacts (`artifacts/analysis`, `report/`) or sync back to Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Runtime diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "gpu-check"},
   "outputs": [],
   "source": [
    "!nvidia-smi || echo 'GPU not available (OK for CPU-only runs)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (Optional) Mount Google Drive\n",
    "If your dataset or checkpoints live on Drive, mount it now. Skip if you plan to upload files manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "mount-drive"},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "MOUNT_DRIVE = False  # set to True if you want to mount Drive\n",
    "if MOUNT_DRIVE:\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Repository + dataset configuration\n",
    "Set the repository URL/branch you want to run. Update paths if your manifest or audio live elsewhere (e.g., in Drive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "config"},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = 'https://github.com/<your-org>/<repo>.git'  # TODO: update\n",
    "BRANCH = 'main'                                        # e.g., 'main' or 'stage1_5'\n",
    "WORKDIR = Path('/content/stage1_5')\n",
    "DATA_ROOT = WORKDIR / 'data'                           # adjust if mounting from Drive\n",
    "MANIFEST_PATH = DATA_ROOT / 'manifest.jsonl'\n",
    "CONFIG_PATH = Path('config/stage1_5.yaml')             # relative to WORKDIR\n",
    "\n",
    "print('Repo:', REPO_URL)\n",
    "print('Branch:', BRANCH)\n",
    "print('Working dir:', WORKDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clone / refresh the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "clone"},
   "outputs": [],
   "source": [
    "import shutil, subprocess\n",
    "if WORKDIR.exists():\n",
    "    shutil.rmtree(WORKDIR)\n",
    "!git clone -b $BRANCH $REPO_URL $WORKDIR\n",
    "%cd $WORKDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "install"},
   "outputs": [],
   "source": [
    "!pip install -q -U pip\n",
    "!pip install -q -e .[dev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (Optional) Sync dataset files\n",
    "Upload or copy your audio + manifest into `data/`. If the files already exist (e.g., synced from Drive), skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "dataset"},
   "outputs": [],
   "source": [
    "# Example: copy dataset from Drive\n",
    "# !cp -r /content/drive/MyDrive/stage1_5_data/* $DATA_ROOT\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    raise FileNotFoundError(f'Manifest not found: {MANIFEST_PATH}. Upload or copy it before continuing.')\n",
    "\n",
    "print('Manifest entries preview:')\n",
    "!head -n 5 $MANIFEST_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature extraction\n",
    "Uncomment the commands you need. You may run them separately to reuse cached features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "features"},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "# Acoustic features\n",
    "stage1_5 features acoustic data/manifest.jsonl artifacts/features/acoustic\n",
    "\n",
    "# ECAPA embeddings (set device to 'cuda' if GPU is available)\n",
    "# stage1_5 features ecapa data/manifest.jsonl artifacts/features/ecapa --device cuda\n",
    "\n",
    "# SSL features (HuBERT/WavLM via s3prl)\n",
    "# stage1_5 features ssl data/manifest.jsonl artifacts/features/ssl --model wavlm_large\n",
    "\n",
    "# Backbone hooks (requires synthetic manifest + text prompts)\n",
    "# stage1_5 features backbone gen/manifest_syn.jsonl data/texts.json artifacts/features/backbone \\\n",
    "#     --checkpoint your-org/tts-backbone --layers encoder_out block_08 decoder_pre_vocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Stage 1.5 pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "run"},
   "outputs": [],
   "source": [
    "!stage1_5 run $CONFIG_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inspect metrics & figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "metrics"},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metrics = pd.read_csv('artifacts/analysis/metrics.csv')\n",
    "metrics.sort_values('accent_f1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "figures"},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image('artifacts/analysis/figures/accent_f1.png'))\n",
    "display(Image('artifacts/analysis/figures/leakage.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. View GO/NOGO report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "report"},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "report_path = Path('report/stage1_5_report.md')\n",
    "if report_path.exists():\n",
    "    display(Markdown(report_path.read_text()))\n",
    "else:\n",
    "    print('Report not found, ensure the pipeline ran successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. (Optional) Sync artifacts back to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "sync"},
   "outputs": [],
   "source": [
    "# Example: copy metrics/report to Drive folder\n",
    "# !cp -r artifacts /content/drive/MyDrive/stage1_5_artifacts\n",
    "# !cp -r report /content/drive/MyDrive/stage1_5_report\n",
    "print('Sync commands commented out by default.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
