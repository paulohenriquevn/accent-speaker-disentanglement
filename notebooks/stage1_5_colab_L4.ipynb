{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéØ Stage 1.5 - Latent Separability Audit\n",
    "\n",
    "## Auditoria de Separabilidade Latente (Accent √ó Speaker) em Backbones TTS\n",
    "\n",
    "**Hardware**: Google Colab L4 GPU (24GB VRAM)  \n",
    "**Tempo estimado**: ~2-3 horas para pipeline completo  \n",
    "**Autor**: OpenCode Research Lab\n",
    "\n",
    "---\n",
    "\n",
    "### üìã O que este notebook faz:\n",
    "\n",
    "1. ‚úÖ **Setup**: Instala depend√™ncias e clona reposit√≥rio\n",
    "2. ‚úÖ **Dataset**: Baixa/prepara dados de √°udio (3 regi√µes brasileiras)\n",
    "3. ‚úÖ **Features**: Extrai representa√ß√µes do backbone TTS (Qwen3-TTS)\n",
    "4. ‚úÖ **Probes**: Treina classificadores lineares (Accent √ó Speaker)\n",
    "5. ‚úÖ **Analysis**: Gera heatmaps e relat√≥rio com decis√£o GO/NOGO\n",
    "\n",
    "### ‚ö° Otimiza√ß√µes para L4:\n",
    "\n",
    "- **Mixed precision**: bfloat16 (reduz VRAM em 50%)\n",
    "- **Flash Attention 3**: kernels otimizados para L4\n",
    "- **Batch processing**: pipeline em lotes\n",
    "- **Cache management**: limpa VRAM entre etapas\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ In√≠cio R√°pido:\n",
    "\n",
    "1. **Runtime** ‚Üí Change runtime type ‚Üí **L4 GPU**\n",
    "2. Execute todas as c√©lulas sequencialmente\n",
    "3. Aguarde ~2h para completar\n",
    "4. Baixe `report/stage1_5_report.md` no final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üîß Parte 1: Setup e Instala√ß√£o\n",
    "\n",
    "Instala todas as depend√™ncias e aplica os fixes cr√≠ticos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Verificar GPU dispon√≠vel\n",
    "!nvidia-smi -L\n",
    "!nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits\n",
    "\n",
    "import torch\n",
    "print(f\"\\nüéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "print(f\"‚úÖ CUDA: {torch.version.cuda}\")\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instalar depend√™ncias (~ 5 min)\n",
    "print(\"üì¶ Instalando depend√™ncias...\\n\")\n",
    "\n",
    "# Instalar PyTorch com CUDA 12.1 (otimizado para L4)\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Instalar Qwen3-TTS\n",
    "!pip install -q -U qwen-tts\n",
    "\n",
    "# Instalar Flash Attention 3 (kernels otimizados para L4)\n",
    "!pip install -q flash-attn --no-build-isolation\n",
    "\n",
    "# Depend√™ncias do Stage 1.5\n",
    "!pip install -q numpy scipy pandas scikit-learn librosa praat-parselmouth soundfile\n",
    "!pip install -q speechbrain transformers datasets huggingface-hub sentence-transformers\n",
    "!pip install -q hydra-core omegaconf tqdm typer pyyaml jinja2\n",
    "!pip install -q matplotlib seaborn\n",
    "\n",
    "print(\"\\n‚úÖ Depend√™ncias instaladas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Clonar reposit√≥rio Stage 1.5 (~ 30 sec)\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/seu-usuario/stage1_5.git\"  # ‚ö†Ô∏è EDITAR COM SEU REPO\n",
    "\n",
    "if not os.path.exists(\"/content/stage1_5\"):\n",
    "    print(f\"üì• Clonando {REPO_URL}...\")\n",
    "    !git clone -q {REPO_URL} /content/stage1_5\n",
    "    print(\"‚úÖ Reposit√≥rio clonado!\")\n",
    "else:\n",
    "    print(\"‚úÖ Reposit√≥rio j√° existe\")\n",
    "\n",
    "%cd /content/stage1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apply-fixes"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Aplicar fixes cr√≠ticos (~ 10 sec)\n",
    "print(\"üîß Aplicando corre√ß√µes cr√≠ticas...\\n\")\n",
    "\n",
    "# Fix 1: Type hints no adapter\n",
    "!sed -i 's/def prepare_inputs(self, entry: ManifestEntry, text: str) -> Dict\\[str, torch.Tensor\\]:/def prepare_inputs(self, entry: ManifestEntry, text: str) -> Dict[str, Any]:/' stage1_5/backbone/huggingface.py\n",
    "\n",
    "# Fix 2: Forward method (aplicar patch completo)\n",
    "fix_forward = '''\n",
    "    def forward(self, inputs: Dict[str, Any]) -> torch.Tensor:\n",
    "        \"\"\"Execute forward pass. For Qwen3-TTS, inputs contains generation params.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            if self._model_type == \"qwen3_tts\":\n",
    "                mode = inputs.get(\"mode\", \"custom_voice\")\n",
    "                if mode == \"custom_voice\":\n",
    "                    self.model.generate_custom_voice(\n",
    "                        text=inputs[\"text\"],\n",
    "                        language=inputs.get(\"language\", \"Portuguese\"),\n",
    "                        speaker=inputs.get(\"speaker\", \"ryan\"),\n",
    "                        instruct=inputs.get(\"instruct\"),\n",
    "                        non_streaming_mode=True,\n",
    "                        max_new_tokens=inputs.get(\"max_new_tokens\", 256),\n",
    "                    )\n",
    "                    return torch.empty(0)\n",
    "                raise ValueError(f\"Unsupported qwen3_tts mode: {mode}\")\n",
    "            return self.model(**inputs)\n",
    "'''\n",
    "\n",
    "# Aplicar via Python (mais seguro que sed)\n",
    "with open(\"stage1_5/backbone/huggingface.py\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Substituir m√©todo forward\n",
    "import re\n",
    "content = re.sub(\n",
    "    r'def forward\\(self, inputs\\):.*?return self\\.model\\(\\*\\*inputs\\)',\n",
    "    fix_forward.strip(),\n",
    "    content,\n",
    "    flags=re.DOTALL\n",
    ")\n",
    "\n",
    "with open(\"stage1_5/backbone/huggingface.py\", \"w\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Fix 3: Layer resolution (adicionar m√©todo se n√£o existir)\n",
    "fix_resolve = '''\n",
    "    def resolve_layer(self, alias: str) -> Optional[torch.nn.Module]:\n",
    "        \"\"\"Resolve layer alias to module.\"\"\"\n",
    "        if self._model_type != \"qwen3_tts\":\n",
    "            modules = dict(self.model.named_modules())\n",
    "            return modules.get(alias)\n",
    "        \n",
    "        modules = dict(self.model.named_modules())\n",
    "        if alias in modules:\n",
    "            return modules[alias]\n",
    "        \n",
    "        aliases_map = {\n",
    "            \"text_encoder_out\": \"talker.text_projection\",\n",
    "            \"pre_vocoder\": \"talker.codec_head\",\n",
    "        }\n",
    "        \n",
    "        if alias in aliases_map:\n",
    "            candidate = aliases_map[alias]\n",
    "            if candidate in modules:\n",
    "                return modules[candidate]\n",
    "        \n",
    "        if alias.startswith(\"decoder_block_\"):\n",
    "            suffix = alias.split(\"decoder_block_\", 1)[1]\n",
    "            if suffix.isdigit():\n",
    "                idx = int(suffix)\n",
    "                candidate = f\"talker.model.layers.{idx}\"\n",
    "                if candidate in modules:\n",
    "                    return modules[candidate]\n",
    "        \n",
    "        return None\n",
    "'''\n",
    "\n",
    "if \"def resolve_layer\" not in content:\n",
    "    # Adicionar antes do √∫ltimo m√©todo\n",
    "    content = content.replace(\n",
    "        \"\\nclass HuggingFaceBackboneAdapter:\",\n",
    "        f\"\\nclass HuggingFaceBackboneAdapter:\\n{fix_resolve}\"\n",
    "    )\n",
    "    with open(\"stage1_5/backbone/huggingface.py\", \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"‚úÖ Fixes aplicados!\")\n",
    "print(\"‚úÖ Instalando pacote...\")\n",
    "\n",
    "# Instalar em modo edit√°vel\n",
    "!pip install -q -e .\n",
    "\n",
    "print(\"\\nüéâ Setup completo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üìä Parte 2: Prepara√ß√£o do Dataset\n",
    "\n",
    "Baixa e prepara dataset de √°udio com 3 regi√µes brasileiras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-dataset"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Op√ß√£o 1: Usar dataset p√∫blico (recomendado)\n",
    "# Baixar Common Voice Brasil ou similar\n",
    "\n",
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è EDITAR: URL do seu dataset (ZIP com √°udios + metadata.csv)\n",
    "DATASET_URL = \"https://exemplo.com/dataset_stage1_5.zip\"\n",
    "\n",
    "# Ou usar dataset sint√©tico para testes\n",
    "USE_SYNTHETIC = True  # Mudar para False para usar dataset real\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    print(\"üß™ Gerando dataset sint√©tico para teste...\\n\")\n",
    "    \n",
    "    # Criar estrutura de diret√≥rios\n",
    "    !mkdir -p data/wav data/splits\n",
    "    \n",
    "    # Gerar √°udios sint√©ticos\n",
    "    import numpy as np\n",
    "    import soundfile as sf\n",
    "    \n",
    "    accents = [\"NE\", \"SE\", \"S\"]\n",
    "    speakers_per_accent = 3\n",
    "    texts_per_speaker = 10\n",
    "    \n",
    "    sr = 16000\n",
    "    duration = 2\n",
    "    \n",
    "    manifest_rows = []\n",
    "    text_rows = []\n",
    "    \n",
    "    for accent in accents:\n",
    "        for spk_idx in range(speakers_per_accent):\n",
    "            speaker = f\"spk{accent}{spk_idx:02d}\"\n",
    "            spk_dir = f\"data/wav/{speaker}\"\n",
    "            os.makedirs(spk_dir, exist_ok=True)\n",
    "            \n",
    "            for text_idx in range(texts_per_speaker):\n",
    "                text_id = f\"t{text_idx:02d}\"\n",
    "                utt_id = f\"{speaker}_{accent}_{text_id}\"\n",
    "                \n",
    "                # Gerar √°udio (ru√≠do branco simples)\n",
    "                audio = np.random.randn(sr * duration).astype(np.float32) * 0.1\n",
    "                wav_path = f\"{spk_dir}/{text_id}.wav\"\n",
    "                sf.write(wav_path, audio, sr)\n",
    "                \n",
    "                # Adicionar ao manifest\n",
    "                manifest_rows.append({\n",
    "                    \"utt_id\": utt_id,\n",
    "                    \"path\": wav_path,\n",
    "                    \"speaker\": speaker,\n",
    "                    \"accent\": accent,\n",
    "                    \"text_id\": text_id,\n",
    "                    \"source\": \"real\"\n",
    "                })\n",
    "                \n",
    "                # Adicionar texto\n",
    "                if {\"text_id\": text_id, \"text\": f\"Texto de exemplo n√∫mero {text_idx}\"} not in text_rows:\n",
    "                    text_rows.append({\n",
    "                        \"text_id\": text_id,\n",
    "                        \"text\": f\"Texto de exemplo n√∫mero {text_idx} para teste de separabilidade\"\n",
    "                    })\n",
    "    \n",
    "    # Salvar manifest\n",
    "    import json\n",
    "    with open(\"data/manifest.jsonl\", \"w\") as f:\n",
    "        for row in manifest_rows:\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    # Salvar textos\n",
    "    with open(\"data/texts.json\", \"w\") as f:\n",
    "        json.dump(text_rows, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset sint√©tico criado:\")\n",
    "    print(f\"   - {len(manifest_rows)} utterances\")\n",
    "    print(f\"   - {len(accents)} accents: {accents}\")\n",
    "    print(f\"   - {accents.count() * speakers_per_accent} speakers\")\n",
    "    print(f\"   - {len(text_rows)} unique texts\")\n",
    "\n",
    "else:\n",
    "    print(f\"üì• Baixando dataset de {DATASET_URL}...\\n\")\n",
    "    !mkdir -p data\n",
    "    !wget -q {DATASET_URL} -O data/dataset.zip\n",
    "    !unzip -q data/dataset.zip -d data/\n",
    "    \n",
    "    # Construir manifest a partir de CSV\n",
    "    # ‚ö†Ô∏è EDITAR: ajustar conforme estrutura do seu dataset\n",
    "    !stage1_5 dataset build-manifest \\\n",
    "        data/metadata.csv \\\n",
    "        --audio-root data/wav \\\n",
    "        --output data/manifest.jsonl\n",
    "    \n",
    "    print(\"‚úÖ Dataset baixado e manifest criado!\")\n",
    "\n",
    "# Verificar dataset\n",
    "!head -3 data/manifest.jsonl\n",
    "!wc -l data/manifest.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "extraction-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üî¨ Parte 3: Extra√ß√£o de Features\n",
    "\n",
    "Extrai features de m√∫ltiplas representa√ß√µes:\n",
    "- Acoustic (MFCC, F0, speaking rate)\n",
    "- ECAPA (speaker embeddings)\n",
    "- SSL (WavLM)\n",
    "- **Backbone (Qwen3-TTS)** ‚Üê foco principal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract-acoustic"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 3.1 Acoustic features (~ 2 min para 100 utterances)\n",
    "print(\"üéµ Extraindo features ac√∫sticas...\\n\")\n",
    "\n",
    "!stage1_5 features acoustic \\\n",
    "    data/manifest.jsonl \\\n",
    "    artifacts/features/acoustic \\\n",
    "    --sample-rate 16000\n",
    "\n",
    "print(\"\\n‚úÖ Acoustic features extra√≠das!\")\n",
    "!ls -lh artifacts/features/acoustic/ | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract-ecapa"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 3.2 ECAPA embeddings (~ 3 min para 100 utterances)\n",
    "print(\"üéôÔ∏è Extraindo ECAPA embeddings...\\n\")\n",
    "\n",
    "!stage1_5 features ecapa \\\n",
    "    data/manifest.jsonl \\\n",
    "    artifacts/features/ecapa \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\n‚úÖ ECAPA embeddings extra√≠dos!\")\n",
    "!ls -lh artifacts/features/ecapa/ | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract-ssl"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 3.3 SSL features (~ 10 min para 100 utterances)\n",
    "print(\"üåê Extraindo SSL features (WavLM)...\\n\")\n",
    "\n",
    "!stage1_5 features ssl \\\n",
    "    data/manifest.jsonl \\\n",
    "    artifacts/features/ssl \\\n",
    "    --model wavlm_large \\\n",
    "    --layers 0 6 12 18 24 \\\n",
    "    --device cuda \\\n",
    "    --torch-dtype bfloat16 \\\n",
    "    --pooling mean\n",
    "\n",
    "print(\"\\n‚úÖ SSL features extra√≠das!\")\n",
    "!ls -lh artifacts/features/ssl/ | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clear-cache-1"
   },
   "outputs": [],
   "source": [
    "# Limpar cache CUDA antes de carregar backbone\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"üíæ VRAM livre: {torch.cuda.mem_get_info()[0] / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extract-backbone"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 3.4 Backbone features (Qwen3-TTS) - ETAPA PRINCIPAL\n",
    "# ~ 30-60 min para 100 utterances (depende da GPU)\n",
    "\n",
    "print(\"üß† Extraindo features do backbone (Qwen3-TTS)...\\n\")\n",
    "print(\"‚ö†Ô∏è  Esta etapa pode demorar. Progresso ser√° mostrado.\\n\")\n",
    "\n",
    "# Checkpoint Qwen3-TTS\n",
    "CHECKPOINT = \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\"\n",
    "\n",
    "# Layers para extrair\n",
    "LAYERS = [\n",
    "    \"text_encoder_out\",\n",
    "    \"decoder_block_04\",\n",
    "    \"decoder_block_08\",\n",
    "    \"decoder_block_12\",\n",
    "    \"pre_vocoder\"\n",
    "]\n",
    "\n",
    "!stage1_5 features backbone \\\n",
    "    data/manifest.jsonl \\\n",
    "    data/texts.json \\\n",
    "    artifacts/features/backbone \\\n",
    "    --checkpoint {CHECKPOINT} \\\n",
    "    --layers {\" \".join(LAYERS)} \\\n",
    "    --device cuda \\\n",
    "    --dtype bfloat16 \\\n",
    "    --attn-implementation flash-attn3 \\\n",
    "    --generation-mode custom_voice \\\n",
    "    --generation-language Portuguese \\\n",
    "    --generation-speaker ryan \\\n",
    "    --generation-max-new-tokens 256 \\\n",
    "    --pooling mean \\\n",
    "    --strict False\n",
    "\n",
    "print(\"\\n‚úÖ Backbone features extra√≠das!\")\n",
    "print(\"\\nüìä Inspecionando features:\")\n",
    "!ls -lh artifacts/features/backbone/ | head -5\n",
    "\n",
    "# Verificar uma feature\n",
    "import numpy as np\n",
    "sample_feat = list(Path(\"artifacts/features/backbone\").glob(\"*.npz\"))[0]\n",
    "data = np.load(sample_feat)\n",
    "print(f\"\\nüì¶ Sample feature: {sample_feat.name}\")\n",
    "print(f\"   Layers: {data.files}\")\n",
    "print(f\"   Shapes: {dict((k, data[k].shape) for k in data.files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "probes-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üéØ Parte 4: Treinamento de Probes\n",
    "\n",
    "Treina classificadores lineares para:\n",
    "- **Accent separability** (speaker-disjoint)\n",
    "- **Speaker identification**\n",
    "- **Leakage tests** (A‚ÜíS, S‚ÜíA)\n",
    "- **Text robustness**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clear-cache-2"
   },
   "outputs": [],
   "source": [
    "# Limpar cache CUDA\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"üíæ VRAM livre: {torch.cuda.mem_get_info()[0] / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-pipeline"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Rodar pipeline completo de probes + an√°lise\n",
    "# ~ 10-20 min\n",
    "\n",
    "print(\"üî¨ Executando pipeline de probes e an√°lise...\\n\")\n",
    "\n",
    "!stage1_5 run config/stage1_5.yaml\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline completo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üìä Parte 5: An√°lise de Resultados\n",
    "\n",
    "Visualiza m√©tricas, heatmaps e decis√£o GO/NOGO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-metrics"
   },
   "outputs": [],
   "source": [
    "# Mostrar m√©tricas\n",
    "import pandas as pd\n",
    "\n",
    "metrics = pd.read_csv(\"artifacts/analysis/metrics.csv\")\n",
    "\n",
    "print(\"üìä M√âTRICAS DE SEPARABILIDADE\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Mostrar top 5 layers por accent F1\n",
    "top5 = metrics.sort_values(\"accent_f1\", ascending=False).head(5)\n",
    "\n",
    "print(\"\\nüèÜ Top 5 Layers por Accent F1 (speaker-disjoint):\\n\")\n",
    "print(top5[[\n",
    "    \"label\",\n",
    "    \"accent_f1\",\n",
    "    \"speaker_acc\",\n",
    "    \"leakage_a2s\",\n",
    "    \"leakage_s2a\",\n",
    "    \"accent_text_drop\"\n",
    "]].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Estat√≠sticas gerais\n",
    "print(\"\\nüìà Estat√≠sticas Gerais:\\n\")\n",
    "print(f\"   - Best Accent F1: {metrics['accent_f1'].max():.3f}\")\n",
    "print(f\"   - Best Speaker Acc: {metrics['speaker_acc'].max():.3f}\")\n",
    "print(f\"   - Min Leakage A‚ÜíS: {metrics['leakage_a2s'].min():.3f}\")\n",
    "print(f\"   - Min Text Drop: {metrics['accent_text_drop'].min():.3f}\")\n",
    "\n",
    "# Comparar backbone vs SSL vs acoustic\n",
    "print(\"\\nüîç Compara√ß√£o por Tipo:\\n\")\n",
    "for feature_type in [\"backbone\", \"ssl\", \"acoustic\", \"ecapa\"]:\n",
    "    subset = metrics[metrics[\"label\"].str.startswith(feature_type)]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"   {feature_type.upper():12s}: F1={subset['accent_f1'].max():.3f} (max)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-heatmaps"
   },
   "outputs": [],
   "source": [
    "# Visualizar heatmaps\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"üé® HEATMAPS\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "heatmaps = [\n",
    "    (\"Accent F1\", \"artifacts/analysis/figures/accent_f1.png\"),\n",
    "    (\"Leakage\", \"artifacts/analysis/figures/leakage.png\"),\n",
    "    (\"Text Robustness\", \"artifacts/analysis/figures/accent_text_robustness.png\"),\n",
    "]\n",
    "\n",
    "for title, path in heatmaps:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"\\nüìä {title}:\\n\")\n",
    "        display(Image(filename=path))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {title} n√£o encontrado em {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-report"
   },
   "outputs": [],
   "source": [
    "# Mostrar relat√≥rio final\n",
    "print(\"üìÑ RELAT√ìRIO FINAL\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with open(\"report/stage1_5_report.md\", \"r\") as f:\n",
    "    report = f.read()\n",
    "\n",
    "# Extrair decis√£o\n",
    "import re\n",
    "decision_match = re.search(r\"\\*\\*Decision:\\*\\* (.+)\", report)\n",
    "rationale_match = re.search(r\"\\*\\*Rationale:\\*\\* (.+)\", report)\n",
    "\n",
    "if decision_match:\n",
    "    decision = decision_match.group(1)\n",
    "    print(f\"\\nüéØ DECIS√ÉO: {decision}\\n\")\n",
    "\n",
    "if rationale_match:\n",
    "    rationale = rationale_match.group(1)\n",
    "    print(f\"üìù Justificativa: {rationale}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nüìÑ Relat√≥rio completo salvo em: report/stage1_5_report.md\")\n",
    "print(\"\\nüíæ Para baixar, use o explorador de arquivos do Colab (√≠cone de pasta √† esquerda)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üíæ Parte 6: Download de Resultados\n",
    "\n",
    "Baixa todos os artefatos gerados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "package-results"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Empacotar resultados\n",
    "print(\"üì¶ Empacotando resultados...\\n\")\n",
    "\n",
    "!zip -r -q stage1_5_results.zip \\\n",
    "    report/ \\\n",
    "    artifacts/analysis/ \\\n",
    "    artifacts/probes/ \\\n",
    "    config/\n",
    "\n",
    "# Estat√≠sticas do arquivo\n",
    "import os\n",
    "size_mb = os.path.getsize(\"stage1_5_results.zip\") / 1e6\n",
    "print(f\"‚úÖ Resultados empacotados: stage1_5_results.zip ({size_mb:.1f} MB)\")\n",
    "\n",
    "# Download via Colab\n",
    "from google.colab import files\n",
    "print(\"\\nüì• Baixando arquivo...\")\n",
    "files.download(\"stage1_5_results.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sync-drive-header"
   },
   "source": [
    "### (Opcional) Sincronizar com Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sync-drive"
   },
   "outputs": [],
   "source": [
    "# Sincronizar com Google Drive (opcional)\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copiar resultados\n",
    "!mkdir -p /content/drive/MyDrive/stage1_5_results\n",
    "!cp -r report/ /content/drive/MyDrive/stage1_5_results/\n",
    "!cp -r artifacts/analysis/ /content/drive/MyDrive/stage1_5_results/\n",
    "!cp stage1_5_results.zip /content/drive/MyDrive/\n",
    "\n",
    "print(\"‚úÖ Resultados sincronizados com Google Drive!\")\n",
    "print(\"üìÇ Localiza√ß√£o: MyDrive/stage1_5_results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üßπ Parte 7: Limpeza (Opcional)\n",
    "\n",
    "Libera espa√ßo em disco e VRAM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup"
   },
   "outputs": [],
   "source": [
    "# Limpar features intermedi√°rias (manter apenas an√°lise)\n",
    "!rm -rf artifacts/features/\n",
    "!rm -rf data/wav/\n",
    "\n",
    "# Limpar cache Python\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Estat√≠sticas de espa√ßo\n",
    "!df -h /content\n",
    "\n",
    "print(\"\\n‚úÖ Limpeza conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### Erro: CUDA out of memory\n",
    "\n",
    "**Solu√ß√£o 1**: Reduzir batch size\n",
    "```python\n",
    "# Editar config/stage1_5.yaml\n",
    "# batch_size: 4  # reduzir para 2 ou 1\n",
    "```\n",
    "\n",
    "**Solu√ß√£o 2**: Usar float16 em vez de bfloat16\n",
    "```bash\n",
    "!stage1_5 features backbone ... --dtype float16\n",
    "```\n",
    "\n",
    "**Solu√ß√£o 3**: Processar em lotes menores\n",
    "```bash\n",
    "# Dividir manifest em chunks\n",
    "!split -l 20 data/manifest.jsonl data/manifest_chunk_\n",
    "# Processar cada chunk separadamente\n",
    "```\n",
    "\n",
    "### Erro: Flash Attention n√£o dispon√≠vel\n",
    "\n",
    "```bash\n",
    "# Remover flag flash-attn3\n",
    "!stage1_5 features backbone ... --attn-implementation eager\n",
    "```\n",
    "\n",
    "### Erro: Qwen-TTS n√£o instalado\n",
    "\n",
    "```bash\n",
    "!pip install -U qwen-tts\n",
    "```\n",
    "\n",
    "### Verificar logs detalhados\n",
    "\n",
    "```python\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Refer√™ncias\n",
    "\n",
    "- **PRD**: `/content/stage1_5/PRD.md`\n",
    "- **GATE**: `/content/stage1_5/GATE_1_5.md`\n",
    "- **README**: `/content/stage1_5/README.md`\n",
    "- **Fixes**: `/mnt/user-data/outputs/IMPLEMENTATION_GUIDE.md`\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Fim!\n",
    "\n",
    "Pipeline Stage 1.5 completo. Pr√≥ximos passos:\n",
    "\n",
    "1. ‚úÖ Analisar `report/stage1_5_report.md`\n",
    "2. ‚úÖ Verificar decis√£o GO/NOGO\n",
    "3. ‚úÖ Se GO ‚Üí prosseguir para Stage 2 (LoRA training)\n",
    "4. ‚úÖ Se NOGO ‚Üí ajustar dataset/backbone conforme recomendado\n",
    "\n",
    "**D√∫vidas?** Consulte a documenta√ß√£o ou abra uma issue no GitHub.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
