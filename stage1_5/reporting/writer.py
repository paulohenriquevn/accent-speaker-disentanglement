"""Report generation utilities."""

from __future__ import annotations

from datetime import datetime
from pathlib import Path
from typing import Any, Dict

import pandas as pd
from jinja2 import Template

from ..analysis import domain_comparison_chart, metric_heatmap
from ..utils.io import ensure_dir


class StageReportWriter:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.template_path = Path(__file__).resolve().parent / "templates" / "stage1_5_report_template.md"

    def generate(self, decision, metrics_df: pd.DataFrame, metrics_path: Path) -> Dict[str, Any]:
        heatmap_dir = Path(self.config["analysis"]["heatmap_dir"])
        figure_accent = metric_heatmap(metrics_df, ["accent_f1"], heatmap_dir / "accent_f1.png", "Accent F1")
        figure_leak = metric_heatmap(metrics_df, ["leakage_a2s", "leakage_s2a"],
                                     heatmap_dir / "leakage.png", "Leakage")
        figure_text = None
        if "accent_text_f1" in metrics_df.columns:
            figure_text = metric_heatmap(
                metrics_df,
                ["accent_text_f1", "accent_text_drop"],
                heatmap_dir / "accent_text_robustness.png",
                "Accent Text Robustness",
            )

        # Domain comparison chart (Real Audio vs SSL vs Backbone)
        figure_comparison = domain_comparison_chart(
            metrics_df,
            heatmap_dir / "domain_comparison.png",
            metric="accent_f1",
        )

        report_path = Path(self.config["paths"]["report"])
        ensure_dir(report_path.parent)

        # Determine LoRA recommendation based on decision
        lora_recommendation = _build_lora_recommendation(decision, metrics_df)
        risk_diagnostic = _build_risk_diagnostic(decision, metrics_df)

        context = {
            "dataset_name": Path(self.config["paths"]["manifest"]).name,
            "date": datetime.utcnow().strftime("%Y-%m-%d"),
            "config_path": str(Path(self.config.get("config_path", "config/stage1_5.yaml")).resolve()),
            "metrics": metrics_df.to_dict("records"),
            "best_layer": decision.label or "N/A",
            "decision": decision.status,
            "rationale": decision.rationale,
            "lora_recommendation": lora_recommendation,
            "risk_diagnostic": risk_diagnostic,
            "notes": "Auto-generated by Stage 1.5 pipeline.",
        }

        template = Template(self.template_path.read_text())
        report_path.write_text(template.render(**context))

        return {
            "decision": decision.status,
            "best_layer": decision.label,
            "metrics_path": str(metrics_path),
            "report_path": str(report_path),
            "figures": {
                "accent": str(figure_accent),
                "leakage": str(figure_leak),
                "text_robustness": str(figure_text) if figure_text else None,
                "domain_comparison": str(figure_comparison),
            },
            "rationale": decision.rationale,
        }


def _build_lora_recommendation(decision, metrics_df: pd.DataFrame) -> str:
    """Build a LoRA insertion recommendation based on probe results."""
    if decision.status == "NOGO":
        return "LoRA insertion not recommended — backbone does not show sufficient accent separability."

    label = decision.label or "N/A"
    parts = [f"Recommended LoRA insertion point: **{label}**"]

    if decision.status == "GO_CONDITIONAL":
        parts.append(
            "This layer shows moderate separability. Consider applying adversarial "
            "regularization during LoRA fine-tuning to reduce speaker–accent entanglement."
        )
    else:
        parts.append(
            "This layer shows strong accent separability with low leakage, "
            "making it a suitable target for accent-conditioned LoRA adaptation."
        )

    return " ".join(parts)


def _build_risk_diagnostic(decision, metrics_df: pd.DataFrame) -> str:
    """Build a risk diagnostic section based on metrics."""
    risks = []

    # Check if leakage is high anywhere
    if "leakage_a2s" in metrics_df.columns:
        max_leak = metrics_df["leakage_a2s"].max()
        if max_leak > 0.5:
            risks.append(
                f"High accent→speaker leakage detected (max {max_leak:.2f}). "
                "Accent and speaker identity may be entangled in some layers."
            )

    if "leakage_s2a" in metrics_df.columns:
        max_leak_s2a = metrics_df["leakage_s2a"].max()
        if max_leak_s2a > 0.5:
            risks.append(
                f"High speaker→accent leakage detected (max {max_leak_s2a:.2f}). "
                "Speaker features may encode accent information, complicating disentanglement."
            )

    # Check text robustness
    if "accent_text_drop" in metrics_df.columns:
        max_drop = metrics_df["accent_text_drop"].max()
        if max_drop > 0.10:
            risks.append(
                f"Text robustness concern: max accent F1 drop under text-disjoint split is {max_drop:.2f} "
                "(threshold: 0.10). Accent predictions may rely on textual cues."
            )

    if decision.status == "NOGO":
        risks.append(
            "Overall separability is below minimum thresholds. "
            "Consider using a different dataset, backbone, or accent definition."
        )

    if not risks:
        return "No significant risks identified. Metrics are within acceptable thresholds."

    return "\n".join(f"- {r}" for r in risks)
